## Swift5 N x M 크기의 2차원 배열 생성 방법
<pre>
    let array: [[Int]] = Array(repeating: Array(repeating: 0, count: m), count: n)
</pre>

## Swift5 for문 거꾸로 순회하는 방법
<pre>
    1. 마지막 순서를 포함하지 않는 경우 - for i in stride(from: 5, to: 0, by: -1) // 5, 4, 3, 2, 1
    2. 마지막 순서를 포함하는 경우 - for i in stride(from: 5, through: 0, by: -1) // 5, 4, 3, 2, 1, 0
</pre>

## 컴퓨터를 공부하면서 반드시 숙지해야 할 것
<pre>
    1. 문제 해결이 목적, 컴퓨터 프로그래밍은 그 수단
    2. 문제해결은 컴퓨터라는 연산 장치로 사람이 빠르게 할 수 없는 연산 같은 것을 컴퓨터로 효율적이게 처리하는 것을 예로 들 수 있음
    3. 프로그래밍 언어란, 사람이 컴퓨터와 소통하기 위한 언어로, 각각의 목적에 따라 여러 종류의 언어가 존재
</pre>

## 프로그램의 실행 단계
<pre>
    1. 인간이 이해할 수 있는 고급 프로그래밍 언어 => 컴파일러 => 어셈블리어 => Binary(0101...) => 프로그램 실행
</pre>

## 변수와 자료형
<pre>
    1. 변수 : 컴퓨터에 데이터를 저장할 공간
    2. 자료형 : 컴퓨터에 저장할 데이터의 형태 : 정수/실수, 문자, 문자열 등
    3. 정수형 변수의 범위 : -21억 ~ 21억(-2^31 ~ 2^31 - 1)
</pre>

## 캐스팅의 개념
<pre>
    1. 같은 자료형 사이의 연산은 그 자료형 연산으로 취급
    2. 다른 자료형 사이의 연산은 더 큰 범위의 연산으로 취급
    3. 즉, 자료형을 임시로 바꾸는 것을 캐스팅이라고 함
</pre>

## 문제를 해결하기 전에 해야할 것
<pre>
    1. 해당 문제에 맞는 설계 후 프로그래밍을 진행해야 정확하고 실수없이 해결할 수 있음
</pre>

## 배열
<pre>
    1. 변수 여러개를 한 번에 선언할 수 있는 방법
    2. 장점 : 데이터에 대한 접근이 빠름, 변수를 일일히 선언하지 않아도 동일한 자료형의 변수를 여러개를 한 번에 저장할 수 있음
    3. 단점 : 데이터에 대한 삽입/삭제 연산이 느림, 정적인 크기 할당
</pre>

## 2차원 배열
<pre>
    1. 2차원 좌표평면과 유사
    2. 가로, 세로가 존재함
</pre>

## 완전 탐색에 대한 이해(Brute-Force Algorithm)
<pre>
    1. 문제 해결하는 방법이 여러가지가 있고, 흔히 사용하는 방법이 몇 가지가 존재함
    2. 그 중 가장 간단한 문제 해결 방법이 완전 탐색
    3. 가능한 모든 경우를 모두 시도해 보는 알고리즘
    4. 완전 탐색을 수행하기 위해서는 모든 경우가 무엇인지 파악하는 것이 중요함
    5. 문제를 접했을 때 가장 먼저 접근해봐야 하는 알고리즘 
</pre>

## 정렬(Sort)
<pre>
    1. 특정 기준을 적용하여 데이터를 나열하는 알고리즘
    2. 오름차순 정렬(갈수록 커지는 것)
    3. 내림차순 정렬(갈수록 작아지는 것)
</pre>

## 기본적인 정렬 알고리즘의 종류
### 선택정렬(Selection Sort)
<pre>
    1. 최솟값을 맨 앞으로 이동시킴(오름차순)
    2. 왼쪽은 정렬이 모두 되었다는 의미
    3. O(N^2)의 시간복잡도를 가짐
    
    for i in 0..<(N - 1) {
        var index: Int = i
        for j in (i + 1)..<N {
            if data[index] > data[j] {
                index = j
            }
        }
        
        let temp: Int = data[index]
        data[index] = data[i]
        data[i] = temp
    }
</pre>

### 삽입정렬(Insertion Sort)
<pre>
    1. 원소를 차례대로 정렬된 배열에 삽입시킴
    2. 왼쪽은 정렬이 모두 되었다는 의미
    3. O(N^2)의 시간복잡도를 가짐
    
    for i in 1...(N - 1) {
        for j in stride(from: i, to: 0, by: -1) {
            if data[j] < data[j - 1] {
                let temp: Int = data[j]
                data[j] = data[j - 1]
                data[j - 1] = temp
            }
        }
    }
</pre>

### 버블정렬(Bubble Sort)
<pre>
    1. 인접한 원소를 비교하여 큰 수를 뒤로 보냄
    2. 오른쪽은 정렬이 모두 되었다는 의미
    3. O(N^2)의 시간복잡도를 가짐
    
    for i in stride(from: N - 1, to: 0, by: - 1) {
        for j in 0...(i - 1) {
            if data[j] > data[j + 1] {
                let temp: Int = data[j]
                data[j] = data[j + 1]
                data[j + 1] = temp
            }
        }
    }
</pre>

## 시간 복잡도(Time Complexity)
<pre>
    1. 문제를 효율적으로 해결
    2. 똑같은 문제를 해결 하더라도 빠르게 해결하는 것이 중요
    3. 시간 복잡도를 계산 함으로써 프로그램을 직접 실행해보지 않더라도 얼마나 빠른지 대략적으로 알 수 있음
    4. O(1), O(N), O(N^2) ... 중 가장 영향력 있는 시간복잡도가 최악의 경우 시간 복잡도를 결정함(최고차항)
    5. 컴퓨터 사양마다 명령을 수행하는데 걸리는 시간은 다 다르지만 비슷하다고 가정 했을 때, 대략 1억번 연산을 수행하는데 1초가 걸림
</pre>

## 기본 정수론(Basic Number Theory)
<pre>
    1. 정수(Integer)의 성질을 연구하는 분야
    2. 가령, 약수와 배수
</pre>

### 약수(Divisor)
<pre>
    특정 정수를 나누어 떨어지게 하는 수
</pre>

### 소수(Prime Number)
<pre>
    약수가 1과 자기 자신 뿐인 정수
</pre>

### 에라토스테네스의 체
<pre>
    1. 소수를 구하는 알고리즘 중 하나
    2. 소수의 배수를 지워 나감으로써 2부터 특정 범위 내의 소수를 얻을 수 있음
    3. O(N log N)의 시간복잡도를 가짐
    4. 2부터 N까지 모든 숫자들 중 모든 소수를 구할 때 사용하면 빠르지만, 특정 수가 소수인지 아닌지 판별할 때는 제곱근 까지 나눠보는 것이 더 빠름 
</pre>

### 소인수 분해
<pre>
    1. 숫자 N을 소수의 곱으로 나타냄
    2. 2부터 시작해서 차례대로 전부 나누어봄(2로 나누어 지는 수는 이미 앞에서 나눌 수 있을 때 까지 다 나누었기 때문에 4로 나누어지지 않는 것이 가능함, 3과 6, 5와 10 마찬가지)
</pre>

### 유클리드 호제법
<pre>
    1. 공약수 : A의 약수 이면서 동시에 B의 약수인 수
    2. 공배수 : A의 배수 이면서 동시에 B의 배수인 수
    3. 최대공약수(GCD, Greatest Common Divisor) : A의 약수 이면서 동시에 B의 약수인 수 중 가장 큰 수
    4. 최소공배수(LCM, Least Common Multiple) : A의 배수 이면서 동시에 B의 배수인 수 중 가장 작은 수
    5. 유클리드 호제법 : 최대공약수를 구하기 위한 알고리즘
    
    func getGCD(_ a: Int, _ b: Int) -> Int {
        return a % b == 0 ? b : getGCD(b, a % b)
    }
}
</pre>

### 파스칼 삼각형
<pre>
    1. 왼쪽 오른쪽 각 대각선 위의 수를 합하여 자신을 결정하는 형태
    2. 조합과 관련이 있음
    3. 경우의 수 문제에서 숫자가 굉장히 큰 경우 활용할 수 있음. 가령, 20 C 10의 끝 3자리 수를 구하는 경우(파스칼 삼각형을 구성할 때, % 1000 연산 하면 됨)
    
    func getPascalTriangle() -> Void {
        let N: Int
        var pascal: [[Int]] = [N + 10][N + 10]
        pascal[0][0] = 1
        
        for i in 1 ~ N {
            pascal[i][0] = 1
            pascal[i][i] = 1
            
            for j in 1 ~ (i - 1) {
                pascal[i][j] = pascal[i - 1][j - 1] + pascal[i - 1][j]
            }
        }
    }
</pre>

## 문자형 변수(Character)
<pre>
    오직 하나의 문자만 담을 수 있는 자료형
</pre>

### 아스키코드
<pre>
    1. 컴퓨터는 문자를 모르기 때문에 숫자로 인식함
    2. 출력할 때만 그 숫자에 대응되는 문자로 출력함
    3. 숫자에 대응되는 문자 정보가 담긴 표를 아스키코드 표라고 함
</pre>

## 문자열(String)
<pre>
    1. 문자만으로 이루어진 배열
    2. 여러 개의 문자를 저장할 수 있음
</pre>

## 함수(Function)
<pre>
    1. 수학에서 어떤 숫자가 들어왔을 때 처리를 해서 출력하는 것
    2. 값을 입력받아 특정 연산을 수행하여 결과를 반환하는 것
    3. Swift 기준 함수 문법
    func 함수이름 -> 반환타입 {
        구현체
        반환값
    }
    
    4. Java 기준 함수(메소드) 문법
    public (static) 반환타입 함수이름 {
        구현체
        반환값
    }
</pre>

### 스코프(Scope)
<pre>
    1. 변수는 선언된 블록 내에서만 접근할 수 있음
    2. 함수간 작업의 완벽한 분담을 위해 스코프가 존재함
</pre>

## 포인터(Pointer)
<pre>
    1. 값을 저장하는 것이 아닌, 값의 위치(메모리 주소)를 저장하는 변수
    2. 해당 주소가 가리키는 곳으로 접근하면 실제 저장되어 있는 값을 알 수 있음
    3. 작성한 코드가 컴퓨터 내부적으로 어떻게 동작하는지에 대한 원리는 반드시 파악하고 있어야 하기 때문에 포인터의 개념이 중요함
</pre>

### 메모리(Memory)
<pre>
    1. 자료의 저장단위 : 비트(Bit), 바이트(Byte), 킬로바이트(KB), 메가바이트(MB), 기가바이트(GB)...
    2. RAM(Random Access Memory) : 자료를 저장하기 위한 장치, 위치마다 접근하는데 걸리는 시간이 비슷하기 때문에 Random이라고 함
    3. PC의 운영체제가 우리가 흔히 알고 있는 64bit 운영체제, 32bit 운영체제라는 것은 메모리 하나의 주소의 크기가 64bit, 32bit라는 것
    4. 즉, 메모리의 주소 하나가 최대로 담을 수 있는 용량이 8Byte(64bit), 4Byte(32bit)라는 말과 동일함
    5. Big Endian, Little Endian : 컴퓨터가 값을 저장하는 순서, 높은 숫자 부터 저장하는 것이 Big Endian, 낮은 숫자부터 저장하는 것이 Little Endian
</pre>

### 운영체제(Operating System)
<pre>
    1. 정의 : 하드웨어를 제어하기 위한 소프트웨어(ex) Linux, MacOS, Windows, iOS, Android...)
</pre>

## Call By Value vs Call By Reference
<pre>
    1. call by value : 값에 의한 호출, 변수의 값을 복사해서 인자로 넘겨줌. 따라서 원본의 값이 변경되지 않음
    2. call by reference: 참조에 의한 호출, 변수의 주소를 인자로 넘겨줌. 따라서 원본의 값이 변경됨
</pre>

### Swift에서의 Array

<img width="490" alt="스크린샷 2022-03-12 16 16 04" src="https://user-images.githubusercontent.com/77099686/158008204-caa533b8-d10c-4e71-a0f3-dd3ca6fe67fb.png">
    
<pre>
    1. Swift에서 Array는 struct 즉, 값 타입이기 때문에 전달인자로 전달될 때 값이 복사돼서 넘어감
    2. Call By Value를 Call By Reference 처럼 사용할 수 있는 방법이 있지만, 권장하지 않음
    3. 단, 아래와 같이 정확한 목적이 있는 경우에는 inout 키워드와 &(주소)값을 넘김으로써 사용할 수도 있음
    
    func swap(_ a: inout Int, _ b: inout Int) -> Void {
        let temp: Int = a
        a = b
        b = a
    }
    
    func solution() -> Void {
        var a: Int = 5
        var b: Int = 10
        
        swap(&a, &b)
        
        print(a, b) // 10, 5
    }
    solution()
</pre>

## 재귀함수(Recursive Function)
<pre>
    1. 자기자신을 부르는 함수
    2. 재귀함수도 함수이기 때문에 값을 입력받아 특정 연산을 수행하여 결과를 반환함
    3. 귀납적 계산 방법을 따름
    4. 귀납적 계산법이란, f(x)를 구하기 위해 또 다시 f(x)를 활용함
    5. 귀납적 계산법은 계산하기 위해 자기자신을 사용하는 식과 멈춰야 하는 기저조건이 존재함
</pre>

### 수학적 귀납법
<pre>
    1. 명제 P(n)이 모든 자연수 n에 대하여 성립함을 보이는 것
    2. 증명 순서 : 1. P(1)이 참임을 보임, 2. P(k)가 성립한다고 가정한 후, P(k + 1)이 성립함을 보임, 3. 따라서 모든 자연수 n에 대하여 P(n)이 성립함
    3. 재귀함수가 정확한 값을 반환하는지 증명하기 위해 수학적 귀납법을 사용함
</pre>

### 재귀함수 디자인 절차
<pre>
    1. 먼저 문제 속에서 재귀적 패턴(자기자신을 사용하는 패턴)을 파악해야 함
    2. 함수의 역할을 말로서 정확하게 정의함
    3. 기저조건에서 함수가 제대로 동작함을 보임
    4. 함수가 제대로 동작한다고 가정하고 함수를 완성함
</pre>

## Back-tracking(Advanced Brute-Force Algorithm)
<pre>
    1. 모든 경우를 시도해 보는 코드를 구현하기가 까다로운 경우
    2. 가령, 문제의 크기 N에 따라 N중 반복문을 구현해야 하는 경우
    3. 재귀호출을 이용하여 편리하게 구현할 수 있음
    4. ex) 순열 구하기
</pre>

### Back-tracking Idea
<pre>
    doRecursion(int x) {
        //x 번째 for문을 실행
        if x > n
            print(numbers)
        else {
            for i = 1 ~ n {
                if 아직 숫자 i가 없다면,
                x번째 for에서 숫자 i를 등록하고,
                doRecursion(x + 1)
            }
        }
    }
</pre>

## 고급 정렬(Advanced Sort)
<pre>
    1. 특정 기준을 적용하여 나열함
    2. 기본 정렬 : 선택 정렬, 삽입 정렬, 버블 정렬
    3. 기본 정렬 시간복잡도 : O(n^2)
    4. O(n log n)만에 정렬할 수 있는 알고리즘 : 합병 정렬, 퀵 정렬, 힙 정렬
</pre>

### 로그의 개념과 그 효율성
<pre>
    1. 로그의 정의 : 지수함수의 역함수, logx(y) = z ----> x ^ z = y
    2. 즉, x를 몇 번 곱해야 y가 되는가?
    3. 컴퓨터공학에서 log를 사용하는 경우, 그 밑이 2 이므로 보통 밑을 생략
    4. log가 있는 경우, 시간 복잡도를 많이 줄일 수 있으므로 효율적인 알고리즘
</pre>

### 합병 정렬(Merge Sort)
<pre>
    1. 재귀호출을 이용함
    2. 배열을 절반으로 나누어 각가을 정렬한 후 합침
    3. 시간 복잡도 : O(n log n)
</pre>

### 합병 정렬의 구현
<pre>
    1. 재귀함수이므로, 재귀함수 디자인 규칙을 따름
    2. void mergeSort(array, start, end)    // array를 start번 째 값 부터 end번 째 값 까지 합병 정렬하는 함수
</pre>

### 퀵 정렬(Quick Sort)
<pre>
    1. 재귀호출을 이용함
    2. 원소를 하나 정하여(pivot), 해당 원소보다 작은 수, 큰 수로 배열을 나눔
    3. 시간 복잡도 : pivot이 원소를 절반으로 나눈다고 가정했을 때, 평균적으로 O(n log n)이고, 원소가 이미 정렬되어 있는 경우(최악의 경우) O(n^2)
</pre>

### 퀵 정렬의 구현
<pre>
    1. 재귀함수이므로, 재귀함수 디자인 규칙을 따름
    2. void quickSort(array, start, end)    // array를 start번 째 값 부터 end번 째 값 까지 퀵 정렬하는 함수
</pre>

## 이진 탐색(Binary Search)
<pre>
    1. 탐색 : 특정 값을 찾음
    2. 이진 탐색 : 정렬되어 있는 값들 중에서 특정 값을 찾는 것
    3. 찾고자 하는 값과 중간 값을 비교하여 절반씩 제거할 수 있음
    4. 숫자를 절반씩 지워나가기 때문에 O(log n)의 시간 복잡도를 가짐
    5. 이미 정렬되어 있다면, 이진 탐색이 굉장히 효율적이고, 정렬을 다시 하더라도 숫자를 엄청 많이 탐색해야 하는 경우에도 효율적임
</pre>

### 이진 탐색의 구현
<pre>
    1. 이미 정렬되어 있다고 가정
    2. 재귀함수를 이용하여 구현할 수도 있고, 단순 반복문을 통해 구현할 수도 있음
    3. 재귀함수 : int binarySearch(array, start, end, value)    //  array의 start번째 값 부터 end번째 값 중 value를 찾는 함수
    4. 단순 반복문 : 투 포인터(start, end)를 활용하여 구현
</pre>

## 매개 변수 탐색(Parametric Search)
<pre>
    1. Binary Search를 이용하여 문제를 해결하는 테크닉
    2. 원래의 값들을 대신할 수 있는 매개변수들이 정렬되어 있는 경우 사용할 수 있음
    3. 원래의 값들을 통해 매개 변수를 구하기 위한 별도 작업이 필요함
</pre>

## 기본 자료구조(Basic Data-Structure)
<pre>
    1. 자료를 저장하는 구조
    2. Stack, Queue, Tree, Graph ...
    3. 특정 목적에 따라 자료를 저장하는 방법이 달라 목적(각 장단점에 의거)에 맞게 사용할 수 있어야 함
    4. 저장되어 있는 자료구조를 바탕으로 의미있는 결과를 도출하는 과정이 알고리즘
    5. 가장 기본이 되는 자료구조 : 변수, 배열
</pre>

### 배열 VS 링크드 리스트
<pre>
    1. 배열의 장점 : 탐색이 빠름
    2. 배열의 단점 : 삽입/삭제 연산이 느림
    3. 링크드 리스트의 장점 : 배열에 비해 삽입/삭제 연산이 빠름
    4. 링크드 리스트의 단점 : 배열에 비해 탐색이 느림 
</pre>

### 캡슐화(Encapsulation)
<pre>
    1. 자료구조 구현의 핵심
    2. 자료구조를 사용하는 사람은 자료구조가 어떻게 동작하는지 알 필요가 없음
    3. 구현한 사람외에 사용하는 사람은 사용법만 알아야 함
</pre>

### 구조체(Struct)
<pre>
    1. 캡슐화를 통해 구현하며, 캡슐화를 구현하기 위해 사용
    2. 하나의 자료형(Type)을 정의할 수 있음
    3. 여러 프로퍼티와 메소드로 이루어져 있어, 관련된 데이터끼리 묶을 수 있음
</pre>

### 스택(Stack)
<pre>
    1. Computer Science의 대표적인 자료구조 중 하나
    2. Linear(선형) 자료구조
    3. 자료를 쌓으면서 저장하는 자료구조
    4. Last In First Out(LIFO) 특징을 가지고 있어, 순서를 뒤집거나 발자취를 기록할 때 사용할 수 있음
    5. Push/Pop 연산이 가능함
    6. Stack Overflow : Stack은 정해진 크기가 있어, 용량이 다 찼음에도 불구하고 데이터를 삽입할 경우 Stack Overflow에러 발생
    7. Stack Underflow : Stack이 비었음에도 불구하고 데이터를 삭제하려고 하는 경우
</pre>

## 큐(Queue)
<pre>
    1. Stack과 함께 Computer Science의 기초 자료구조 중 하나
    2. First In First Out(FIFO) 구조
    3. Linear(선형) 자료구조
    4. Queue Overflow : Queue의 용량보다 데이터를 더 넣으려고 하는 경우
    5. Queue Underflow : Queue에 데이터가 없는데 데이터를 삭제하려고 하는 경우
    6. 단순 투 포인터로 큐를 구현하게 되는 경우 push / pop 연산시 두 포인터가 모두 증가만 하게되므로. 앞의 공간에 대한 낭비가 발생할 수 있음
</pre>

### 원형 큐의 개념과 구현방법(Circular Queue)
<pre>
    1. 선형큐의 공간 낭비의 단점을 해결하기 위한 큐
    2. 선형큐에 비해 공간 활용 능력이 우수
    3. 원소의 개수를 유지하는 별도의 변수가 필요함
    4. front, rear 투 포인터가 끝에 도달하게되면 push / pop 연산시 다시 처음으로 되돌리는 원형의 형태
</pre>

## 스택 & 큐 정리(Stack & Queue Summary)
<pre>
    1. 특정 자료구조가 무엇인지 아는 것은 중요하지 않고, 의도에 맞게 사용하는 능력이 중요함
    2. 올바른 괄호 판단 문제는 대표적인 stack 자료구조를 활용하는 문제
    3. Stack과 Queue에는 상태(status) 즉, 해야하는 작업이 저장됨
    4. Stack의 경우, 함수 호출에 대한 복귀 주소 즉, 발자취를 기록을 해두며, 이를 Call Stack이라고 함(Stack의 Scheduling, 재귀호출)
    5. Queue의 경우, Stack과 달리 상태의 의존관계가 없을 때, 즉 해야 하는 작업을 진행할 때 다른 작업에 영향을 받지 않고 순서대로 처리하며, 대표적으로 스케쥴링, 병렬화에 많이 사용됨
</pre>

## 트리(Tree)
<pre>
    1. 트리 역시 자료를 담는 Computer Science의 기초 자료구조 중 하나
    2. 계층형(Hierarchy) 자료구조
    3. 정점(Node), 간선(Edge)로 이루어져 있으며, 간선은 두 정점을 잇는 선
    4. 부모와 자식관계를 가지며 레벨은 높이를 뜻함
    5. 트리는 그 안에 또 트리가 존재하며(재귀적 성질), 이를 서브트리(Subtree)라고 함
    6. 최상위 부모노드를 root라고 함
</pre>

### 트리의 순회(Tree Traversal)
<pre>
    1. 트리 내에 어떠한 자료가 담겨 있는지를 알기 위한 방법
    2. 순회하는 방법은 많지만, 재귀적 성질을 이용해서 순회하는 방법이 젤 중요함
</pre>

### 이진 트리 재귀적 순회 방법
<pre>
    1. 자식노드가 2개 이하인 트리를 Binary Tree(이진 트리)라고 함
    2. 전위 순회 : Root - L(Left Subtree) - R(Right Subtree)
    3. 중위 순회 : L(Left Subtree) - Root - R(Right Subtree)
    4. 후위 순회 : L(Left Subtree) - R(Right Subtree) - Root
    5. 세가지 순회방법이 목적은 트리 내의 자료를 탐색하는 것으로 같지만, 특성이 다름
</pre>

## 우선순위 큐(Priority Queue)
<pre>
    1. Tree를 활용하는 대표적인 예제
    2. 원소를 제거할 때, 우선순위가 가장 높은 원소를 제거
    3. 배열로 우선순위 큐를 구현하게 되면, 삽입 연산은 효율적이지만 삭제 연산의 경우 비효율적일 수 있음
</pre>

### 힙(Heap)
<pre>
    1. 부모의 값이 항상 자식보다 우선순위가 높은 완전이진트리
    2. 자식노드가 2개 이하인 이진트리 이면서, 값이 왼쪽부터 채워지는 트리를 완전이진트리라고 함
    3. 힙에 값을 삽입하게 되면, 완전이진트리 특성에 따라 왼쪽부터 채워지고, 부모와 자식 사이의 우선순위를 비교하여 트리를 재구성해야 함
    4. 노드가 n개일 때, 높이가 대략 log n이므로 높이가 1개 증가할 때 마다 노드는 약 2배 증가하게 됨
    5. 즉, 삽입 연산 시 최악의 경우 트리의 높이 만큼 비교 연산을 수행 하므로, O(log n)의 시간복잡도를 가짐
    6. 힙에서 삭제 연산을 하게 되면, 우선순위가 가장 높은 root를 삭제하고, 가장 끝에 있는 자식 노드를 root로 옮기고 우선순위를 비교하여 트리를 재구성해야 함
    7. 삽입 연산과 마찬가지로 root에서 최대로 트리의 높이 만큼 내려올 수 있으므로, O(log n)의 시간복잡도를 가짐  
</pre>

### 우선순위 큐의 구현 요약

|-|배열|힙|
|------|---|---|
|값의 삽입|O(1)|O(log n)|
|값의 삭제|O(n)|O(log n)|
|값의 탐색|O(n)|O(1)|

<pre>
   1. 삽입 연산이 배열이 빠르긴 하지만, 삭제 연산에서 차이가 많이 발생하므로, 우선순위 큐를 구현해야 한다면 힙으로 구현하는 것이 바람직함
   2. 힙의 경우 완전이진트리이기 때문에, 배열을 이용하여 구현할 수 있음
</pre>
